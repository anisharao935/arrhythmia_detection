{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def load_mitbih_dataset(path):\n",
    "    # Define annotation list\n",
    "    annots_list = ['N', 'L', 'R', 'e', 'j', 'S', 'A', 'a', 'J', 'V', 'E', 'F', '/', 'f', 'Q']\n",
    "    annots_5_class = {'N': 0, 'L': 0, 'R': 0, 'e': 0, 'j': 0, 'A':0, 'a':1, 'J':1, 'S':1, 'V':2, 'E':2, 'F':3, 'f':3, '/':4, 'Q':4}\n",
    "\n",
    "    normal = []\n",
    "    # This will hold the signal segments corresponding to beats\n",
    "    X = []\n",
    "    # This will hold the binary labels corresponding to each beat\n",
    "    y = []\n",
    "\n",
    "    # Get the list of record names from the 'RECORDS' file\n",
    "    record_list = []\n",
    "    with open(os.path.join(path, 'RECORDS'), 'r') as file:\n",
    "        record_list = [line.strip() for line in file]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    # Process each record\n",
    "    for record_name in record_list:\n",
    "        # Load the record and its annotation\n",
    "        record = wfdb.rdrecord(os.path.join(path, record_name))\n",
    "        annotation = wfdb.rdann(os.path.join(path, record_name), 'atr')\n",
    "\n",
    "        # Get the signal and annotation values\n",
    "        signal = record.p_signal[:, 0]  # assuming you only want the first signal\n",
    "        beat_annotations = annotation.symbol\n",
    "        beat_locations = annotation.sample\n",
    "\n",
    "        # Iterate over each beat annotation\n",
    "        for sym, loc in zip(beat_annotations, beat_locations):\n",
    "            # Check if the annotation symbol is in the classes of interest\n",
    "            if sym in annots_list:\n",
    "                # 5-class classification\n",
    "                label = annots_5_class[sym]\n",
    "                \n",
    "                # Define a window size around each beat\n",
    "                win_size = 625  # This gives a window of 1250 samples around the beat\n",
    "                # Avoid going out of bounds\n",
    "                if loc - win_size >= 0 and loc + win_size <= len(signal):\n",
    "                    segment = signal[loc - win_size: loc + win_size]\n",
    "                    segment = scaler.fit_transform(segment.reshape(-1, 1)).flatten()\n",
    "                    # if (label==0):\n",
    "                    #     normal.append((segment, label))\n",
    "                    # else:\n",
    "                    X.append(segment)\n",
    "                    y.append(label)\n",
    "\n",
    "    # for elem in random.sample(normal, (len(normal))//2):\n",
    "    #     X.append(elem[0])\n",
    "    #     y.append(elem[1])\n",
    "\n",
    "    # Convert lists to numpy arrays for ML processing\n",
    "    X = np.array(X)\n",
    "    y = to_categorical(y, num_classes=5)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data_2D(X):\n",
    "    # Reshape data from 1D to 2D format \n",
    "    num_samples = X.shape[0]\n",
    "    X_reshaped = X.reshape(num_samples, 25, 50, 1)\n",
    "    return X_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data_1D(X):\n",
    "    # Reshape data from 2D to 1D format \n",
    "    num_samples = X.shape[0]\n",
    "    X_reshaped = X.reshape(num_samples, 1250, 1)\n",
    "    return X_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this step just onceeeeeeeeee, next time just load from the saved train test\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X, y = load_mitbih_dataset(\"/home/anishar5/anisha/Research-Work/mit-bih-dataset\")\n",
    "\n",
    "# Convert one-hot encoded labels back to single integer labels\n",
    "y_int = np.argmax(y, axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train_int, y_test_int = train_test_split(X, y_int, test_size=0.20, random_state=42, stratify=y_int)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_res, y_train_res_int = smote.fit_resample(X_train, y_train)\n",
    "#X_train_res = reshape_data_2D(X_train_res)\n",
    "#X_test = reshape_data_2D(X_test)\n",
    "\n",
    "# Convert resampled integer labels back to one-hot encoding\n",
    "y_train_res = to_categorical(y_train_res_int, num_classes=5)\n",
    "\n",
    "# Convert test integer labels to one-hot encoding\n",
    "y_test = to_categorical(y_test_int, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({0: 74398, 2: 5782, 4: 5634, 3: 1427, 1: 188})\n",
      "Class distribution after SMOTE: Counter({0: 188, 1: 188, 2: 188, 3: 188, 4: 188})\n",
      "Test class distribution: Counter({0: 18600, 2: 1445, 4: 1409, 3: 357, 1: 47})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "y_train_list = y_train_int.tolist()\n",
    "y_train_res_list = y_train_res_int.tolist()\n",
    "\n",
    "print(f'Original class distribution: {Counter(y_train_list)}')\n",
    "print(f'Class distribution after SMOTE: {Counter(y_train_res_list)}')\n",
    "\n",
    "print(f'Test class distribution: {Counter(y_test_int.tolist())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Perform the split once\n",
    "\n",
    "# Step 2: Save the split data to disk\n",
    "np.save('./X_train_AS.npy', X_train_res)\n",
    "np.save('./X_test_AS.npy', X_test)\n",
    "np.save('./y_train_AS.npy', y_train_res)\n",
    "np.save('./y_test_AS.npy', y_test)\n",
    "\n",
    "# In future sessions, you can load the datasets directly from the saved files:\n",
    "X_train = np.load('./X_train_AS.npy')\n",
    "X_test = np.load('./X_test_AS.npy')\n",
    "y_train = np.load('./y_train_AS.npy')\n",
    "y_test = np.load('./y_test_AS.npy')\n",
    "\n",
    "# Use X_train, X_test, y_train, y_test for model training and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 anishar5 anishar5  218580128 Jul 19 15:28 X_test_BS.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5  125580128 Jul 19 14:11 X_test_DS.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5  218580128 Jul 22 16:19 X_test_ENN.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5  218580128 Jul  5 16:29 X_test_SMOTE.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5 3719900128 Jul 19 15:28 X_train_BS.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5 1859950128 Jul 19 14:11 X_train_DS.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5 3664230128 Jul 22 16:19 X_train_ENN.npy\n",
      "-rw-r--r-- 1 anishar5 anishar5 3719900128 Jul  5 16:29 X_train_SMOTE.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5     437288 Jul 19 15:28 y_test_BS.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5     251288 Jul 19 14:11 y_test_DS.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5     437288 Jul 22 16:19 y_test_ENN.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5     437288 Jul  5 16:29 y_test_SMOTE.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5    7439928 Jul 19 15:28 y_train_BS.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5    3720028 Jul 19 14:11 y_train_DS.npy\n",
      "-rw-rw-r-- 1 anishar5 anishar5    7328588 Jul 22 16:19 y_train_ENN.npy\n",
      "-rw-r--r-- 1 anishar5 anishar5    7439928 Jul  5 16:29 y_train_SMOTE.npy\n"
     ]
    }
   ],
   "source": [
    "!ls -l *.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Saved Train-Test Split\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, ReLU, TimeDistributed, Flatten, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Load the saved datasets\n",
    "X_train = np.load('./X_train_BS.npy')\n",
    "X_test = np.load('./X_test_BS.npy')\n",
    "y_train = np.load('./y_train_BS.npy')\n",
    "y_test = np.load('./y_test_BS.npy')\n",
    "\n",
    "X_train = reshape_data_2D(X_train)\n",
    "X_test = reshape_data_2D(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21858, 25, 50, 1)\n",
      "(21858, 5)\n",
      "(371990, 25, 50, 1)\n",
      "(371990, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining my Model\n",
    "#network.py\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, ReLU, TimeDistributed, Flatten, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_lstm_model(input_shape=(1250, 1)):\n",
    "    # No need to pass num_classes for binary classification\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    x11 = Conv1D(filters=3, kernel_size=31, strides=5, padding='same', activation=None, use_bias=True)(inputs)\n",
    "    x12 = Conv1D(filters=3, kernel_size=36, strides=5, padding='same', activation=None, use_bias=True)(inputs)\n",
    "    x13 = Conv1D(filters=3, kernel_size=41, strides=5, padding='same', activation=None, use_bias=True)(inputs)\n",
    "    conv = keras.layers.concatenate([x11, x12, x13], axis=-1)\n",
    "\n",
    "    # Batch normalization and ReLU activation\n",
    "    x = BatchNormalization()(conv)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # LSTM layer\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    x = LSTM(200, return_sequences=False)(x)  # Adjust return_sequences based on whether you're adding more LSTM layers or not\n",
    "\n",
    "    # Dense layers for classification\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(20, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    \n",
    "    # Adjusted for binary classification: single output neuron, sigmoid activation\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs=[inputs], outputs=[outputs], name=\"lstm_model\")\n",
    "    \n",
    "    # Compile the model with binary crossentropy loss and include 'Precision' and 'Recall' in metrics\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_18 (Conv2D)          (None, 23, 48, 258)       2580      \n",
      "                                                                 \n",
      " leaky_re_lu_30 (LeakyReLU)  (None, 23, 48, 258)       0         \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 11, 24, 258)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 10, 23, 645)       666285    \n",
      "                                                                 \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 10, 23, 645)       0         \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 5, 11, 645)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 2, 8, 126)         1300446   \n",
      "                                                                 \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 2, 8, 126)         0         \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 1, 4, 126)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 504)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 30)                15150     \n",
      "                                                                 \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 30)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 20)                620       \n",
      "                                                                 \n",
      " leaky_re_lu_34 (LeakyReLU)  (None, 20)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 5)                 105       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,985,186\n",
      "Trainable params: 1,985,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "\n",
    "def load_2D_CNN(input_shape=(25, 50, 1)):\n",
    "\n",
    "    # Hyperparameters from the paper\n",
    "    learning_rate = 3e-3\n",
    "    momentum = 0.7\n",
    "    regularization_param = 0.2\n",
    "\n",
    "    # Define the Sequential model\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Layer 0–1: Convolutional Layer\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=258, \n",
    "        kernel_size=(3, 3), \n",
    "        strides=(1, 1), \n",
    "        activation=None,  # Activation added separately to specify LeakyReLU\n",
    "        input_shape=input_shape,  \n",
    "        kernel_regularizer=regularizers.l2(regularization_param)\n",
    "    ))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))  # Adding LeakyReLU activation\n",
    "\n",
    "    # Layer 1–2: Max-Pooling Layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 2–3: Convolutional Layer\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=129*5, \n",
    "        kernel_size=(2, 2), \n",
    "        strides=(1, 1), \n",
    "        activation=None,\n",
    "        kernel_regularizer=regularizers.l2(regularization_param)\n",
    "    ))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 3–4: Max-Pooling Layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 4–5: Convolutional Layer\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=126, \n",
    "        kernel_size=(4, 4), \n",
    "        strides=(1, 1), \n",
    "        activation=None,\n",
    "        kernel_regularizer=regularizers.l2(regularization_param)\n",
    "    ))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 5–6: Max-Pooling Layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten the output before fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Layer 6–7: Fully-Connected Layer\n",
    "    model.add(layers.Dense(30, activation='linear', kernel_regularizer=regularizers.l2(regularization_param)))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 7–8: Fully-Connected Layer\n",
    "    model.add(layers.Dense(20, activation='linear', kernel_regularizer=regularizers.l2(regularization_param)))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 8–9: Fully-Connected Layer (Output Layer)\n",
    "    model.add(layers.Dense(5, activation='softmax'))  # Assuming a classification problem with 5 classes\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy','Precision', 'Recall']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "x = load_2D_CNN()\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 23, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 23, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 23, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 11, 24, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 9, 22, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 9, 22, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 9, 22, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 4, 11, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 2, 9, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 2, 9, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 2, 9, 256)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 256)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 412,933\n",
      "Trainable params: 412,037\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "\n",
    "def load_simplified_2D_CNN(input_shape=(25, 50, 1)):\n",
    "    # Hyperparameters from the paper\n",
    "    learning_rate = 3e-3\n",
    "    momentum = 0.7\n",
    "    regularization_param = 0.1\n",
    "\n",
    "    # Define the Sequential model\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Layer 0–1: Convolutional Layer\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=64, \n",
    "        kernel_size=(3, 3), \n",
    "        strides=(1, 1), \n",
    "        activation=None, \n",
    "        input_shape=input_shape,  \n",
    "        kernel_regularizer=regularizers.l2(regularization_param)\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 1–2: Max-Pooling Layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 2–3: Convolutional Layer\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=128, \n",
    "        kernel_size=(3, 3), \n",
    "        strides=(1, 1), \n",
    "        activation=None,\n",
    "        kernel_regularizer=regularizers.l2(regularization_param)\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 3–4: Max-Pooling Layer\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Layer 4–5: Convolutional Layer\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=256, \n",
    "        kernel_size=(3, 3), \n",
    "        strides=(1, 1), \n",
    "        activation=None,\n",
    "        kernel_regularizer=regularizers.l2(regularization_param)\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 5–6: Global Average Pooling Layer\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # Layer 6–7: Fully-Connected Layer\n",
    "    model.add(layers.Dense(128, activation='linear', kernel_regularizer=regularizers.l2(regularization_param)))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 7–8: Fully-Connected Layer\n",
    "    model.add(layers.Dense(64, activation='linear', kernel_regularizer=regularizers.l2(regularization_param)))\n",
    "    model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "    # Layer 8–9: Fully-Connected Layer (Output Layer)\n",
    "    model.add(layers.Dense(5, activation='softmax'))  # Assuming a classification problem with 5 classes\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy', 'Precision', 'Recall']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "x = load_simplified_2D_CNN()\n",
    "x.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 417, 128)          6528      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 417, 128)         512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 208, 128)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 208, 32)           28704     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 208, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 104, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 104, 32)           10272     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 104, 128)          20608     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 52, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 52, 256)           491776    \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 26, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 26, 512)           655872    \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 26, 128)           196736    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3328)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1704448   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,118,149\n",
      "Trainable params: 3,117,829\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "def load_1D_CNN():\n",
    "\n",
    "    # Define the Sequential model\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Layer 1: Conv1D with 128 filters of size 50, activation ReLU, stride 3\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=50,  # Kernel size adapted to input length\n",
    "        strides=3,  # Stride adjusted for larger input length\n",
    "        activation='relu',\n",
    "        padding='same',  # Keep same padding to maintain the sequence length\n",
    "        input_shape=(1250, 1)  # Updated input shape\n",
    "    ))\n",
    "\n",
    "    # Layer 2: Batch Normalization\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Layer 3: MaxPooling1D with pool size 2, stride 2\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    # Layer 4: Conv1D with 32 filters of size 7, activation ReLU, stride 1\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=32,\n",
    "        kernel_size=7,  # Smaller kernel size to capture finer details\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='same'  # Same padding to keep the sequence length consistent\n",
    "    ))\n",
    "\n",
    "    # Layer 5: Batch Normalization\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Layer 6: MaxPooling1D with pool size 2, stride 2\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    # Layer 7: Conv1D with 32 filters of size 10, activation ReLU, stride 1\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=32,\n",
    "        kernel_size=10,  # Kernel size adapted for capturing medium range patterns\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='same'  # Keep same padding to avoid reducing the sequence length\n",
    "    ))\n",
    "\n",
    "    # Layer 8: Conv1D with 128 filters of size 5, activation ReLU, stride 1\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=5,\n",
    "        strides=1,  # Reduced stride to prevent downsampling too quickly\n",
    "        activation='relu',\n",
    "        padding='same'  # Same padding to maintain sequence length\n",
    "    ))\n",
    "\n",
    "    # Layer 9: MaxPooling1D with pool size 2, stride 2\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    # Layer 10: Conv1D with 256 filters of size 15, activation ReLU, stride 1\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=256,\n",
    "        kernel_size=15,  # Larger kernel size for wider feature detection\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='same'  # Same padding to keep the sequence length consistent\n",
    "    ))\n",
    "\n",
    "    # Layer 11: MaxPooling1D with pool size 2, stride 2\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    # Layer 12: Conv1D with 512 filters of size 5, activation ReLU, stride 1\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=512,\n",
    "        kernel_size=5,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='same'  # Same padding to avoid reducing the sequence length too much\n",
    "    ))\n",
    "\n",
    "    # Layer 13: Conv1D with 128 filters of size 3, activation ReLU, stride 1\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=3,  # Small kernel size for fine details\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='same'  # Keep same padding to avoid reducing the sequence length\n",
    "    ))\n",
    "\n",
    "    # Layer 14: Flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Layer 15: Dense layer with 512 units, activation ReLU, dropout rate 0.1\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "\n",
    "    # Layer 16: Dense layer with softmax activation for output\n",
    "    model.add(layers.Dense(5, activation='softmax'))  # Adjust the number of output classes as necessary\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "x = load_1D_CNN()\n",
    "# Print the model summary\n",
    "x.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anishar5/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1250, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 1250, 32)     128         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1250, 32)    128         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 1250, 32)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 1250, 32)     3104        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 1250, 32)    128         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 1250, 32)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 1250, 32)     3104        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1250, 32)    128         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1250, 32)     0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  're_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 1250, 32)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 625, 32)      0           ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 625, 32)     128         ['max_pooling1d[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 625, 32)      0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 625, 32)      3104        ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 625, 32)     128         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 625, 32)      0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 625, 32)      3104        ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 625, 32)     128         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 625, 32)      0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  're_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 625, 32)      0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 312, 32)     0           ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 312, 32)     128         ['max_pooling1d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 312, 32)      0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 312, 32)      3104        ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 312, 32)     128         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 312, 32)      0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 312, 32)      3104        ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 312, 32)     128         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 312, 32)      0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  're_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 312, 32)      0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 156, 32)     0           ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 156, 32)     128         ['max_pooling1d_2[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 156, 32)      0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4992)         0           ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          639104      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 5)            325         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 667,717\n",
      "Trainable params: 667,077\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, initializers\n",
    "\n",
    "# Define the residual convolutional block\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = layers.Conv1D(filters, kernel_size, strides=stride, padding='same', \n",
    "                      kernel_initializer=initializers.HeNormal(), \n",
    "                      kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters, kernel_size, strides=stride, padding='same', \n",
    "                      kernel_initializer=initializers.HeNormal(), \n",
    "                      kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Define the model\n",
    "def create_rescnn(input_shape=(1250, 1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # First residual block\n",
    "    x = layers.Conv1D(32, kernel_size=3, strides=1, padding='same', \n",
    "                      kernel_initializer=initializers.HeNormal(), \n",
    "                      kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    x = residual_block(x, 32)\n",
    "    x = layers.MaxPooling1D(pool_size=2, strides=2, padding='valid')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Second residual block\n",
    "    x = residual_block(x, 32)\n",
    "    x = layers.MaxPooling1D(pool_size=2, strides=2, padding='valid')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Third residual block\n",
    "    x = residual_block(x, 32)\n",
    "    x = layers.MaxPooling1D(pool_size=2, strides=2, padding='valid')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # Flatten and add dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu', \n",
    "                     kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.Dense(64, activation='relu', \n",
    "                     kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    outputs = layers.Dense(5, activation='softmax')(x)  # Assuming 5 classes\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Instantiate and compile the model\n",
    "input_shape = (1250, 1)  # Modify as necessary\n",
    "model = create_rescnn(input_shape)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 50, 8)         136       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 25, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 25, 13)        429       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 13, 13)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 13, 13)         689       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 7, 13)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 364)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 364)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               46720     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,555\n",
      "Trainable params: 56,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "\n",
    "def CNN2D_second(input_shape=(25, 50, 1)):\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional Block 1\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    model.add(Conv2D(13, (2, 2), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    model.add(Conv2D(13, (2, 2), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # Flatten the output\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dropout for regularization\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Fully Connected Layer 1\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    # Fully Connected Layer 2\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model summary\n",
    "input_shape = (25, 50, 1)\n",
    "model = CNN2D_second(input_shape)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 25, 50, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 25, 50, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 25, 50, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 25, 50, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 25, 50, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 25, 50, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 25, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 25, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 25, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 13, 25, 32)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 25, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 25, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 13, 25, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 13, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 13, 32)         9248      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 13, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 7, 13, 32)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2912)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               372864    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,461\n",
      "Trainable params: 411,141\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def create_gcnn_model(input_shape=(25, 50, 1)):\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional Block C1\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Convolutional Block C2\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Pooling Layer P1\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # Convolutional Block C3\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Convolutional Block C4\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Pooling Layer P2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # Convolutional Block C5\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example of model compilation and summary\n",
    "input_shape = (25, 50, 1)\n",
    "model = create_gcnn_model(input_shape)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 25, 128)          58880     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,325\n",
      "Trainable params: 168,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, ReLU, MaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Softmax\n",
    "\n",
    "def load_lstm(input_shape=(25,50)):\n",
    "    # Define the model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Bidirectional LSTM Block\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape))\n",
    "    model.add((LSTM(64, return_sequences=False)))\n",
    "\n",
    "    # Dense Layers\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(5, activation='softmax'))  # Assuming 5 classes for the softmax layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model summary\n",
    "x = load_lstm()\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " signal (InputLayer)            [(None, 1250, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 1250, 64)     1024        ['signal[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 1250, 64)    256         ['conv1d_14[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1250, 64)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 1250, 128)    131072      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 1250, 128)   512         ['conv1d_16[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 1250, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1250, 128)    0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 313, 64)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 313, 128)     262144      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 313, 128)     8192        ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 313, 128)     0           ['conv1d_17[0][0]',              \n",
      "                                                                  'conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 313, 128)    512         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 313, 128)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 313, 128)     0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 313, 196)     401408      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 313, 196)    784         ['conv1d_19[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 313, 196)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 313, 196)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_9 (MaxPooling1D)  (None, 79, 128)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 79, 196)      614656      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 79, 196)      25088       ['max_pooling1d_9[0][0]']        \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 79, 196)      0           ['conv1d_20[0][0]',              \n",
      "                                                                  'conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 79, 196)     784         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 79, 196)      0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 79, 196)      0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 79, 256)      802816      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 79, 256)     1024        ['conv1d_22[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 79, 256)      0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 79, 256)      0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_10 (MaxPooling1D  (None, 20, 196)     0           ['add_1[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 20, 256)      1048576     ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 20, 256)      50176       ['max_pooling1d_10[0][0]']       \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 20, 256)      0           ['conv1d_23[0][0]',              \n",
      "                                                                  'conv1d_21[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 20, 256)     1024        ['add_2[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 20, 256)      0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 20, 256)      0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 20, 320)      1310720     ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 20, 320)     1280        ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 20, 320)      0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 20, 320)      0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_11 (MaxPooling1D  (None, 4, 256)      0           ['add_2[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 4, 320)       1638400     ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 4, 320)       81920       ['max_pooling1d_11[0][0]']       \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 4, 320)       0           ['conv1d_26[0][0]',              \n",
      "                                                                  'conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 4, 320)      1280        ['add_3[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 4, 320)       0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 4, 320)       0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1280)         0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 5)            6405        ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,390,053\n",
      "Trainable params: 6,386,325\n",
      "Non-trainable params: 3,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization, Activation, Add, Flatten, Dense)\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ResidualUnit(object):\n",
    "    \"\"\"Residual unit block (unidimensional).\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples_out: int\n",
    "        Number of output samples.\n",
    "    n_filters_out: int\n",
    "        Number of output filters.\n",
    "    kernel_initializer: str, optional\n",
    "        Initializer for the weights matrices. See Keras initializers. By default it uses\n",
    "        'he_normal'.\n",
    "    dropout_keep_prob: float [0, 1), optional\n",
    "        Dropout rate used in all Dropout layers. Default is 0.8\n",
    "    kernel_size: int, optional\n",
    "        Kernel size for convolutional layers. Default is 17.\n",
    "    preactivation: bool, optional\n",
    "        When preactivation is true use full preactivation architecture proposed\n",
    "        in [1]. Otherwise, use architecture proposed in the original ResNet\n",
    "        paper [2]. By default it is true.\n",
    "    postactivation_bn: bool, optional\n",
    "        Defines if you use batch normalization before or after the activation layer (there\n",
    "        seems to be some advantages in some cases:\n",
    "        https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md).\n",
    "        If true, the batch normalization is used before the activation\n",
    "        function, otherwise the activation comes first, as it is usually done.\n",
    "        By default it is false.\n",
    "    activation_function: string, optional\n",
    "        Keras activation function to be used. By default 'relu'.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] K. He, X. Zhang, S. Ren, and J. Sun, \"Identity Mappings in Deep Residual Networks,\"\n",
    "           arXiv:1603.05027 [cs], Mar. 2016. https://arxiv.org/pdf/1603.05027.pdf.\n",
    "    .. [2] K. He, X. Zhang, S. Ren, and J. Sun, \"Deep Residual Learning for Image Recognition,\" in 2016 IEEE Conference\n",
    "           on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770-778. https://arxiv.org/pdf/1512.03385.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_samples_out, n_filters_out, kernel_initializer='he_normal',\n",
    "                 dropout_keep_prob=0.8, kernel_size=17, preactivation=True,\n",
    "                 postactivation_bn=False, activation_function='relu'):\n",
    "        self.n_samples_out = n_samples_out\n",
    "        self.n_filters_out = n_filters_out\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.dropout_rate = 1 - dropout_keep_prob\n",
    "        self.kernel_size = kernel_size\n",
    "        self.preactivation = preactivation\n",
    "        self.postactivation_bn = postactivation_bn\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def _skip_connection(self, y, downsample, n_filters_in):\n",
    "        \"\"\"Implement skip connection.\"\"\"\n",
    "        # Deal with downsampling\n",
    "        if downsample > 1:\n",
    "            y = MaxPooling1D(downsample, strides=downsample, padding='same')(y)\n",
    "        elif downsample == 1:\n",
    "            y = y\n",
    "        else:\n",
    "            raise ValueError(\"Number of samples should always decrease.\")\n",
    "        # Deal with n_filters dimension increase\n",
    "        if n_filters_in != self.n_filters_out:\n",
    "            # This is one of the two alternatives presented in ResNet paper\n",
    "            # Other option is to just fill the matrix with zeros.\n",
    "            y = Conv1D(self.n_filters_out, 1, padding='same',\n",
    "                       use_bias=False, kernel_initializer=self.kernel_initializer)(y)\n",
    "        return y\n",
    "\n",
    "    def _batch_norm_plus_activation(self, x):\n",
    "        if self.postactivation_bn:\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            x = BatchNormalization(center=False, scale=False)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(self.activation_function)(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"Residual unit.\"\"\"\n",
    "        x, y = inputs\n",
    "        n_samples_in = y.shape[1]\n",
    "        downsample = n_samples_in // self.n_samples_out\n",
    "        n_filters_in = y.shape[2]\n",
    "        y = self._skip_connection(y, downsample, n_filters_in)\n",
    "        # 1st layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, padding='same',\n",
    "                   use_bias=False, kernel_initializer=self.kernel_initializer)(x)\n",
    "        x = self._batch_norm_plus_activation(x)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # 2nd layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, strides=downsample,\n",
    "                   padding='same', use_bias=False,\n",
    "                   kernel_initializer=self.kernel_initializer)(x)\n",
    "        if self.preactivation:\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            y = x\n",
    "            x = self._batch_norm_plus_activation(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "            y = x\n",
    "        return [x, y]\n",
    "\n",
    "\n",
    "def load_dnn(n_classes, input_shape, last_layer='sigmoid'):\n",
    "    kernel_size = 16\n",
    "    kernel_initializer = 'he_normal'\n",
    "    signal = Input(shape=input_shape, dtype=np.float32, name='signal')\n",
    "    x = signal\n",
    "    x = Conv1D(64, kernel_size, padding='same', use_bias=False,\n",
    "               kernel_initializer=kernel_initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x, y = ResidualUnit(input_shape[0] // 4, 128, kernel_size=kernel_size, kernel_initializer=kernel_initializer)([x, x])\n",
    "    x, y = ResidualUnit(input_shape[0] // 16, 196, kernel_size=kernel_size, kernel_initializer=kernel_initializer)([x, y])\n",
    "    x, y = ResidualUnit(input_shape[0] // 64, 256, kernel_size=kernel_size, kernel_initializer=kernel_initializer)([x, y])\n",
    "    x, _ = ResidualUnit(input_shape[0] // 256, 320, kernel_size=kernel_size, kernel_initializer=kernel_initializer)([x, y])\n",
    "    x = Flatten()(x)\n",
    "    diagn = Dense(n_classes, activation=last_layer, kernel_initializer=kernel_initializer)(x)\n",
    "    model = Model(signal, diagn)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_dnn(5, (1250, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: './model_checkpoint.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m checkpoint_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model_checkpoint.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# List all files in the checkpoint directory\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m checkpoint_files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(checkpoint_dir)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Regular expression to extract the epoch number from the filename\u001b[39;00m\n\u001b[1;32m     11\u001b[0m epoch_regex \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_epoch_(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: './model_checkpoint.keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Path to the directory where checkpoints are saved\n",
    "checkpoint_dir = './model_checkpoint.keras'\n",
    "\n",
    "# List all files in the checkpoint directory\n",
    "checkpoint_files = os.listdir(checkpoint_dir)\n",
    "\n",
    "# Regular expression to extract the epoch number from the filename\n",
    "epoch_regex = r\"_epoch_(\\d+)_\"\n",
    "\n",
    "# Initialize a list to store the epoch numbers\n",
    "epochs = []\n",
    "\n",
    "# Iterate over the checkpoint filenames\n",
    "for filename in checkpoint_files:\n",
    "    match = re.search(epoch_regex, filename)\n",
    "    if match:\n",
    "        # Extract the epoch number and convert it to an integer\n",
    "        epoch_num = int(match.group(1))\n",
    "        epochs.append(epoch_num)\n",
    "\n",
    "# Find the maximum epoch number (last saved epoch)\n",
    "if epochs:\n",
    "    last_saved_epoch = max(epochs)\n",
    "    print(f\"The last saved epoch was: {last_saved_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoints found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Initializing a new model...\n",
      "Training model\n",
      "Epoch 1/15\n",
      "11625/11625 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.8960 - precision: 0.9376 - recall: 0.8677\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94588, saving model to ./model_checkpoint.keras\n",
      "11625/11625 [==============================] - 467s 40ms/step - loss: 0.2665 - accuracy: 0.8960 - precision: 0.9376 - recall: 0.8677 - val_loss: 0.1623 - val_accuracy: 0.9459 - val_precision: 0.9491 - val_recall: 0.9435\n",
      "Epoch 2/15\n",
      "11625/11625 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9878 - precision: 0.9884 - recall: 0.9873\n",
      "Epoch 2: val_accuracy improved from 0.94588 to 0.97543, saving model to ./model_checkpoint.keras\n",
      "11625/11625 [==============================] - 463s 40ms/step - loss: 0.0412 - accuracy: 0.9878 - precision: 0.9884 - recall: 0.9873 - val_loss: 0.0930 - val_accuracy: 0.9754 - val_precision: 0.9760 - val_recall: 0.9745\n",
      "Epoch 3/15\n",
      "11625/11625 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9928 - precision: 0.9932 - recall: 0.9926\n",
      "Epoch 3: val_accuracy improved from 0.97543 to 0.97740, saving model to ./model_checkpoint.keras\n",
      "11625/11625 [==============================] - 463s 40ms/step - loss: 0.0262 - accuracy: 0.9928 - precision: 0.9932 - recall: 0.9926 - val_loss: 0.0893 - val_accuracy: 0.9774 - val_precision: 0.9783 - val_recall: 0.9769\n",
      "Epoch 4/15\n",
      "11625/11625 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9944 - precision: 0.9947 - recall: 0.9942\n",
      "Epoch 4: val_accuracy improved from 0.97740 to 0.98705, saving model to ./model_checkpoint.keras\n",
      "11625/11625 [==============================] - 463s 40ms/step - loss: 0.0207 - accuracy: 0.9944 - precision: 0.9947 - recall: 0.9942 - val_loss: 0.0700 - val_accuracy: 0.9871 - val_precision: 0.9872 - val_recall: 0.9869\n",
      "Epoch 5/15\n",
      "11625/11625 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9954 - precision: 0.9956 - recall: 0.9951\n",
      "Epoch 5: val_accuracy improved from 0.98705 to 0.98801, saving model to ./model_checkpoint.keras\n",
      "11625/11625 [==============================] - 463s 40ms/step - loss: 0.0177 - accuracy: 0.9954 - precision: 0.9956 - recall: 0.9951 - val_loss: 0.0589 - val_accuracy: 0.9880 - val_precision: 0.9883 - val_recall: 0.9878\n",
      "Epoch 6/15\n",
      "11625/11625 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9962 - precision: 0.9964 - recall: 0.9961\n",
      "Epoch 6: val_accuracy did not improve from 0.98801\n",
      "11625/11625 [==============================] - 463s 40ms/step - loss: 0.0148 - accuracy: 0.9962 - precision: 0.9964 - recall: 0.9961 - val_loss: 0.0740 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9876\n",
      "Epoch 7/15\n",
      "11624/11625 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9965 - precision: 0.9967 - recall: 0.9963\n",
      "Epoch 7: val_accuracy did not improve from 0.98801\n",
      "11625/11625 [==============================] - 463s 40ms/step - loss: 0.0136 - accuracy: 0.9965 - precision: 0.9967 - recall: 0.9963 - val_loss: 0.0605 - val_accuracy: 0.9877 - val_precision: 0.9887 - val_recall: 0.9871\n",
      "Epoch 8/15\n",
      "10777/11625 [==========================>...] - ETA: 33s - loss: 0.0123 - accuracy: 0.9968 - precision: 0.9970 - recall: 0.9967"
     ]
    }
   ],
   "source": [
    "#Compiling and Training the Model\n",
    "import os\n",
    "from tensorflow import keras\n",
    "\n",
    "# Calculate class weights for balancing the training\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train.argmax(axis=1)), y=y_train.argmax(axis=1))\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Check if a checkpoint exists\n",
    "load_existing = False\n",
    "checkpoint_path = './model_checkpoint.keras'\n",
    "if os.path.exists(checkpoint_path) and load_existing:\n",
    "    print(\"Loading previously saved model...\")\n",
    "    model = keras.models.load_model(checkpoint_path)\n",
    "    # Manually set the initial_epoch parameter based on how many epochs were previously run\n",
    "    initial_epoch = 13  # Adjust this based on your last saved epoch\n",
    "else:\n",
    "    print(\"No checkpoint found. Initializing a new model...\")\n",
    "    #model = create_lstm_model(input_shape=(1250, 1))\n",
    "    #model = load_1D_CNN()\n",
    "    #model = create_gcnn_model()\n",
    "    #model = load_simplified_2D_CNN()\n",
    "    #model = CNN2D_second()\n",
    "    #model = load_dnn(5, (1250, 1))\n",
    "    model = load_lstm()\n",
    "    #model = create_rescnn((1250, 1))\n",
    "    initial_epoch = 0\n",
    "\n",
    "# Continue with the compilation, setup your callbacks and start training\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,  # Consider setting this to False if you want to save after every epoch regardless of performance\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1)\n",
    "\n",
    "print(\"Training model\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=15,  # Total number of epochs you aim to train\n",
    "    initial_epoch=initial_epoch,  # Start from the epoch after the last saved one\n",
    "    batch_size=32,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    "    class_weight=class_weight_dict)\n",
    "\n",
    "# Optionally, save the final model\n",
    "final_model_path = 'final_model.keras'\n",
    "model.save(final_model_path)\n",
    "print(f\"Model saved to {final_model_path}\")\n",
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anishar5/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, 25, 128)          58880     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,325\n",
      "Trainable params: 168,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('./model_checkpoint.keras')\n",
    "#model = load_model('./dnn_final.keras')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 12s 15ms/step - loss: 0.0589 - accuracy: 0.9880 - precision: 0.9883 - recall: 0.9878\n",
      "Test Loss: 0.05892636254429817\n",
      "Test Accuracy: 0.9880135655403137\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Model on Test Data\n",
    "eval_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {eval_results[0]}\")\n",
    "print(f\"Test Accuracy: {eval_results[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684/684 [==============================] - 11s 15ms/step\n",
      "[0 0 0 0 0 0 0 4 0 4 0 4 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 4]\n"
     ]
    }
   ],
   "source": [
    "#Generating Predictions\n",
    "y_pred_probs = model.predict(X_test)\n",
    "#y_pred = np.round(y_pred_probs).astype(int)  # Assuming a binary classification\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "print(y_pred[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99     18600\n",
      "           S       0.68      0.40      0.51        47\n",
      "           V       0.93      0.97      0.95      1445\n",
      "           F       0.87      0.83      0.85       357\n",
      "           Q       0.99      0.99      0.99      1409\n",
      "\n",
      "    accuracy                           0.99     21858\n",
      "   macro avg       0.89      0.84      0.86     21858\n",
      "weighted avg       0.99      0.99      0.99     21858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating and Printing the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_classes, y_pred, target_names=['N', 'S', 'V', 'F', 'Q']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Learning Curves (Loss vs Epoch)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Summarize history for accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
